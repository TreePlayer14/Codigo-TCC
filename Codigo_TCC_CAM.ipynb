{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Codigo_TCC_CAM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqW0EVVg3rK4U4ozvEE3gi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e3e71dcdf3ef4f91b03e8e044cbc2cd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5ae6441081164e079b5e6b7a0216e06d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ddcaee968e9a44288500d495dc9a7d0d",
              "IPY_MODEL_d880c88ef4c84e21a3b656fa8280114e",
              "IPY_MODEL_abe42a0d4aa04757922e48f8a6e91767"
            ]
          }
        },
        "5ae6441081164e079b5e6b7a0216e06d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ddcaee968e9a44288500d495dc9a7d0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a2a8e57966a34efc872a8abcbfe745fe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9bbfad5b064d4b6bb6faaecbbeb9ee8f"
          }
        },
        "d880c88ef4c84e21a3b656fa8280114e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c35ee13d3d254b3180a6daed4486e47c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102530333,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102530333,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22a89fd4a8e64cbeab50fc580bead0cd"
          }
        },
        "abe42a0d4aa04757922e48f8a6e91767": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_11c0706a0a7448f19761a678ef83b0e9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:03&lt;00:00, 25.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b69f9f10bab645fa89145c6e5270c6c5"
          }
        },
        "a2a8e57966a34efc872a8abcbfe745fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9bbfad5b064d4b6bb6faaecbbeb9ee8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c35ee13d3d254b3180a6daed4486e47c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22a89fd4a8e64cbeab50fc580bead0cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "11c0706a0a7448f19761a678ef83b0e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b69f9f10bab645fa89145c6e5270c6c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TreePlayer14/Codigo-TCC/blob/main/Codigo_TCC_CAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS6Mrta9g3s-"
      },
      "source": [
        "File Handling:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeCDqvJ-cGj9"
      },
      "source": [
        "from PIL import Image\n",
        "from pandas import DataFrame\n",
        "import os \n",
        "\n",
        "class Arff:\n",
        "    \"\"\"Structure that holds an arff file\n",
        "    \n",
        "        Attrs:\n",
        "            relation (string): File content description.\n",
        "            attrs (list of strings): List of attribute names.\n",
        "            attr_types (list of strings): List of attribute types.\n",
        "            entries (list of lists): Arff data.\n",
        "            classes (list of int): Classes on the file.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.relation = \"\"\n",
        "        self.attrs = []\n",
        "        self.attr_types = []\n",
        "        self.entries = []\n",
        "        self.classes = []\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.entries)\n",
        "\n",
        "def readImage(path):\n",
        "    \"\"\"Open an image using PIL\"\"\"\n",
        "    try:\n",
        "        return Image.open(path)\n",
        "    except OSError as err:\n",
        "        print(\"Couldn't read file. Error: {0}\".format(err))\n",
        "\n",
        "def createFolderContentCsv(folder_path: str, csv_name:str, extension:str=None):\n",
        "    \"\"\"Create a csv file with the contents of a folder\n",
        "        Args:\n",
        "            folder_path(string): path to folder\n",
        "            csv_name(string): output csv file name, without extension\n",
        "            extension(string): filter only files of a kind on the output csv. \n",
        "    \"\"\"\n",
        "    if os.path.isdir(folder_path):\n",
        "        output_file_path = os.path.join(folder_path,csv_name)+'.csv'\n",
        "        if os.path.isfile(output_file_path):\n",
        "            print(\"There's already a csv file with given name. name: {}\".format(csv_name))\n",
        "            return\n",
        "\n",
        "        content_list = os.listdir(folder_path)\n",
        "        file_list = []\n",
        "        for content in content_list:\n",
        "            if os.path.isfile(os.path.join(folder_path, content)):\n",
        "                file_list.append(content)\n",
        "        if extension:\n",
        "            temp_list = []\n",
        "            for f in file_list:\n",
        "                if f.endswith(extension):\n",
        "                    temp_list.append(f)\n",
        "            file_list = temp_list\n",
        "        \n",
        "        df = DataFrame(file_list)\n",
        "        df.to_csv(output_file_path, header=False, index=False)\n",
        "    else:\n",
        "        print(\"Folder doesn't exist. path: {}\".format(folder_path))\n",
        "\n",
        "def createArffFile(file_name: str, content: list, attrs: list, classes: list, target:str = None):\n",
        "    \"\"\"Create a arff file with given data list\n",
        "        Args:\n",
        "            file_name(string): name of output file without extension\n",
        "            content(list): data to write in arff, must be a two-dimensional list. Function assumes all values are real numbers\n",
        "            attrs(list): list with the attribute names for the content. Classes are not included here, and should be put at the end of the each content entry\n",
        "            classes(list): list with possible classes of given data\n",
        "            target(string): path to the target folder of the output file, if none is passed assumes the current directory   \n",
        "    \"\"\"\n",
        "    if target == None:\n",
        "        target = os.getcwd()\n",
        "    \n",
        "    output_path = os.path.join(target,file_name) + \".arff\"\n",
        "\n",
        "    if os.path.isfile(output_path):\n",
        "        raise Exception(\"There's already a file with given name at target folder. File name: {}\" .format(file_name))\n",
        "\n",
        "    line_count = len(content)\n",
        "\n",
        "    if line_count == 0:\n",
        "        raise Exception(\"The content list is empty!\")\n",
        "\n",
        "    attr_count = len(content[0])\n",
        "\n",
        "    if len(classes) == 0:\n",
        "        raise Exception(\"Must send at least one class!\")\n",
        "\n",
        "    if attr_count == 0:\n",
        "        raise Exception(\"Didn't find values for any attribute on the content list\")\n",
        "    elif attr_count-1 != len(attrs):\n",
        "        raise Exception(\"Mismatching size of attribute name list and received content. Found {} atributes and {} names\".format(attr_count-1,len(attrs)))\n",
        "\n",
        "    f = open(output_path, \"x\")\n",
        "    f.write(\"@RELATION '\" + file_name + \".arff'\\n\\n\")\n",
        "\n",
        "    for name in attrs:\n",
        "        f.write(\"@ATTRIBUTE \" + name + \" numeric\\n\")\n",
        "\n",
        "    classes_as_strings = [str(x) for x in classes]\n",
        "    joined_classes = \",\".join(classes_as_strings)\n",
        "\n",
        "    f.write(\"@ATTRIBUTE class {\" + joined_classes + \"}\\n\\n\")\n",
        "    f.write(\"@DATA\\n\\n\")\n",
        "\n",
        "    for entry in content:\n",
        "        content_as_string = [str(x) for x in entry]\n",
        "        joined_content = \",\".join(content_as_string)\n",
        "        f.write(joined_content+\"\\n\")\n",
        "    \n",
        "    f.close()\n",
        "    \n",
        "def readArff(path:str):\n",
        "    \"\"\"Reads the content of an arff file to and arff object\n",
        "    \n",
        "    Args:\n",
        "        path(str): Arff file path.\n",
        "\n",
        "    Returns:\n",
        "        Arff type object\n",
        "    \"\"\"\n",
        "    if os.path.isfile(path) == False:\n",
        "        raise Exception(\"File doesn't exist. path: {}\".format(path))\n",
        "\n",
        "    obj = Arff()\n",
        "\n",
        "    f = open(path, \"r\")\n",
        "    line = f.readline()\n",
        "    reading_entries = False\n",
        "    while line != '':\n",
        "        # skips line breaks\n",
        "        if line == \"\\n\":\n",
        "            line = f.readline()\n",
        "            continue\n",
        "\n",
        "        # clean text\n",
        "        line = line.strip()\n",
        "\n",
        "        if reading_entries:\n",
        "            entries = line.split(\",\")\n",
        "            if len(entries) != (len(obj.attrs) + 1):\n",
        "                raise Exception(\"Found entry with more data than specified attributes!\")\n",
        "            \n",
        "            entry_list = []\n",
        "            for idx in range(len(obj.attr_types)):\n",
        "                if obj.attr_types[idx].lower() == \"numeric\" or obj.attr_types[idx].lower() == \"real\":\n",
        "                    entry_list.append(float(entries[idx]))\n",
        "                else:\n",
        "                    entry_list.append(entries[idx])\n",
        "                    \n",
        "            #gets class at the end\n",
        "            entry_class = int(entries[-1])\n",
        "            if entry_class not in obj.classes:\n",
        "                raise Exception(\"Read entry with a class different from the ones especified. \\nExpected: {}\\nGot: {}\".format(obj.classes, entry_class))\n",
        "            entry_list.append(entry_class)\n",
        "\n",
        "            if len(obj) == 0:\n",
        "                obj.entries = [entry_list]\n",
        "            else:\n",
        "                obj.entries.append(entry_list)\n",
        "        else:\n",
        "            if line.lower().startswith(\"@relation\"):\n",
        "                splitted_line = line.split(\" \")\n",
        "                obj.relation = splitted_line[1].replace(\"'\",\"\")\n",
        "            elif line.lower().startswith(\"@attribute\"):\n",
        "                splitted_line = line.split(\" \")\n",
        "                if splitted_line[1].lower() == 'class':\n",
        "                    classes = splitted_line[2].replace(\"{\",\"\").replace(\"}\",\"\")\n",
        "                    obj.classes = [int(num) for num in classes.split(\",\")]\n",
        "                else:\n",
        "                    obj.attrs.append(splitted_line[1])\n",
        "                    obj.attr_types.append(splitted_line[2])\n",
        "            elif line.lower().startswith(\"@data\"):\n",
        "                reading_entries = True\n",
        "\n",
        "        line = f.readline() \n",
        "    \n",
        "    f.close()\n",
        "\n",
        "    return obj\n",
        "\n",
        "def mergeArffs(arff1:Arff, arff2: Arff):\n",
        "    \"\"\"Combine two arff objects into one and write it to a target\n",
        "\n",
        "    Args:\n",
        "        arff1(Arff): First arff.\n",
        "        arff2(Arff): Second arff.\n",
        "\n",
        "    Returns:\n",
        "        Combined Arff object \n",
        "    \"\"\"\n",
        "    if len(arff1) != len(arff2):\n",
        "        raise Exception(\"Can't combine arffs with different data length.\")\n",
        "\n",
        "    if arff1.classes != arff2.classes:\n",
        "        raise Exception(\"Can't combine arffs with different classes.\")\n",
        "\n",
        "    combined = Arff()\n",
        "    combined.classes = arff1.classes\n",
        "    combined.relation = \"Merged_{}_and_{}\".format(arff1.relation,arff2.relation)\n",
        "    combined.attrs = arff1.attrs + arff2.attrs\n",
        "    combined.attr_types = arff1.attr_types + arff2.attr_types\n",
        "    for idx in range(len(arff1)):\n",
        "        if arff1.entries[idx][-1] != arff2.entries[idx][-1]:\n",
        "            raise Exception(\"Failed combining entries. Class missmatch at index {}\".format(idx))\n",
        "        combined_entry = arff1.entries[idx][:-1] + arff2.entries[idx]\n",
        "        if len(combined) == 0:\n",
        "            combined.entries = [combined_entry]\n",
        "        else:\n",
        "            combined.entries.append(combined_entry)\n",
        "    \n",
        "    return combined\n",
        "\n",
        "def concatArffs(arff1:Arff, arff2: Arff):\n",
        "    \"\"\"Concatenate two arff objects into one and write it to a target\n",
        "\n",
        "    Args:\n",
        "        arff1(Arff): First arff.\n",
        "        arff2(Arff): Second arff.\n",
        "\n",
        "    Returns:\n",
        "        Concatenated Arff object \n",
        "    \"\"\"\n",
        "    if len(arff1.attrs) != len(arff2.attrs):\n",
        "        raise Exception(\"Can't combine arffs with different number of atributes. First arff has {}, and second has {}\".format(len(arff1.attrs), len(arff2.attrs)))\n",
        "\n",
        "    for idx in range(len(arff1.attrs)):\n",
        "        if(arff1.attrs[idx] != arff2.attrs[idx]):\n",
        "            raise Exception(\"Mismatching attribute name at column {}\".format(idx))\n",
        "        if(arff1.attr_types[idx] != arff2.attr_types[idx]):\n",
        "            raise Exception(\"Mismatching attribute types at column {}\".format(idx))\n",
        "\n",
        "    if arff1.classes != arff2.classes:\n",
        "        raise Exception(\"Can't combine arffs with different classes.\")\n",
        "\n",
        "    concatenated = Arff()\n",
        "    concatenated.classes = arff1.classes\n",
        "    concatenated.relation = \"Concatenated_{}_and_{}\".format(arff1.relation,arff2.relation)\n",
        "    concatenated.attrs = arff1.attrs\n",
        "    concatenated.attr_types = arff1.attr_types\n",
        "    concatenated.entries = arff1.entries + arff2.entries\n",
        "        \n",
        "    return concatenated\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXdhjLH13Dc9"
      },
      "source": [
        "Código para treinar a rede neural:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_nIRvPG2-dE"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import copy\n",
        "import random\n",
        "\n",
        "\n",
        "def trainCrossValidation(model, dataset, k:int, error_criterion, optmization_algorithm, epochs:int, plot_acc = False, plot_loss = False, datasetOnGpu = False):\n",
        "    \"\"\" Trains a torchvision model using k-folds cross-validation.\n",
        "\n",
        "    Args:\n",
        "        model(torchvision.models): Neural network model.\n",
        "        dataset(Dataset.ImageDataset): Dataset to train.\n",
        "        k(int): Number of folds, must be at least 2.\n",
        "        error_criterion(torch.nn.modules.loss): Error function for the training.\n",
        "        optmization_algorithm(torch.optim): Optimization rule for backpropagation.\n",
        "        epochs(int): Number of training iteration for each fold.\n",
        "        plot_acc(bool): Plot average epoch accuracy for training and evaluation after training is complete.\n",
        "        plot_loss(bool): Plot average epoch loss for training and evaluation after training is complete.\n",
        "        datasetOnGpu(bool): If the input is already loaded on the GPU\n",
        "\n",
        "    Output:\n",
        "        Trained model with the weights that got the highest accuracy in the evaluation while training\n",
        "    \"\"\"\n",
        "    # Gets execution start timestamp\n",
        "    since = time.time()\n",
        "    \n",
        "    #Start epoch history track\n",
        "    train_acc_hist = []\n",
        "    train_loss_hist = []\n",
        "    eval_acc_hist = []\n",
        "    eval_loss_hist = []\n",
        "\n",
        "    #Transfer model to GPU if available\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda()\n",
        "\n",
        "    # Save untrained model to reset every fold\n",
        "    untrained_model_weights = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    # Starts best model and accuracy to current values\n",
        "    best_model_weights = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    \n",
        "    img_count = len(dataset) # get image count\n",
        "    img_idx_list = [i for i in range(img_count)] # create list with image indexes\n",
        "    random.shuffle(img_idx_list) # shuffle the list\n",
        "\n",
        "    # Separate data in folds\n",
        "    fold_size = len(img_idx_list) // k # get fold size\n",
        "    folds = [img_idx_list[i*fold_size:(i+1)*fold_size] for i in range(k)] # separate in equally sized folds\n",
        "    left_out = len(img_idx_list) % k # count left out indexes\n",
        "    # distribute left out indexes into folds\n",
        "    for idx in range(left_out):\n",
        "        folds[idx].append(img_idx_list[-1*(idx+1)])\n",
        "\n",
        "    for current_fold in range(k):\n",
        "        fold_start_time = time.time()\n",
        "        fold_best_acc = 0.0\n",
        "        fold_train_acc_hist = []\n",
        "        fold_train_loss_hist = []\n",
        "        fold_eval_acc_hist = []\n",
        "        fold_eval_loss_hist = []\n",
        "\n",
        "        # get list with all other folds\n",
        "        other_folds = []\n",
        "        for i in range(k):\n",
        "            if i == current_fold:\n",
        "                continue\n",
        "            other_folds += folds[i]\n",
        "        # Create tensor batch with training images and their labels\n",
        "        training_inputs = []\n",
        "        training_labels = []\n",
        "        for i in range(len(other_folds)):\n",
        "            training_inputs.append(dataset[other_folds[i]])\n",
        "            training_labels.append(dataset.getExpected(other_folds[i]))\n",
        "        training_inputs = torch.stack(training_inputs)\n",
        "        training_labels = torch.stack(training_labels)\n",
        "        \n",
        "        # Create tensor batch with evaluation images and their labels\n",
        "        eval_inputs = []\n",
        "        eval_labels = []\n",
        "        for i in range(len(folds[current_fold])):\n",
        "            eval_inputs.append(dataset[folds[current_fold][i]])\n",
        "            eval_labels.append(dataset.getExpected(folds[current_fold][i]))    \n",
        "        eval_inputs = torch.stack(eval_inputs)\n",
        "        eval_labels = torch.stack(eval_labels)\n",
        "\n",
        "        # Start epoch iterations\n",
        "        for epoch in range(epochs):\n",
        "            print('-' * 10)\n",
        "            print('Fold {}/{} - Epoch {}/{}'.format(current_fold +1, k, epoch + 1, epochs))\n",
        "            epoch_start_time = time.time()\n",
        "\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    model.train()  # Set model to training mode\n",
        "                    # Get inputs for phase\n",
        "                    input_data = training_inputs\n",
        "                    input_labels = training_labels\n",
        "                else:\n",
        "                    model.eval()   # Set model to evaluate mode\n",
        "                    # Get inputs for phase\n",
        "                    input_data = eval_inputs\n",
        "                    input_labels = eval_labels\n",
        "\n",
        "                # Transfer inputs to GPU if available\n",
        "                if torch.cuda.is_available():\n",
        "                    input_labels = input_labels.cuda()\n",
        "                    if datasetOnGpu == False:\n",
        "                        input_data = input_data.cuda()\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optmization_algorithm.zero_grad()\n",
        "\n",
        "                # Process the input\n",
        "                output = model(input_data)\n",
        "                # Get it's predictions                \n",
        "                _, preds = torch.max(output, 1)\n",
        "                # Calculate batch loss\n",
        "                loss = error_criterion(output, input_labels)\n",
        "\n",
        "                # If training apply backward + optimize to adust weights\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optmization_algorithm.step()\n",
        "\n",
        "                # Get correct predictions\n",
        "                _,correct_labels = torch.max(input_labels,1)\n",
        "\n",
        "                # Get epoch global loss, count correct predictions and get accuracy\n",
        "                epoch_correct_evals = torch.sum(preds == correct_labels)\n",
        "                epoch_loss = loss.item() / len(input_data)\n",
        "                epoch_acc = float(epoch_correct_evals) / len(input_data)\n",
        "\n",
        "                # Save data to history\n",
        "                if phase == 'val':\n",
        "                    fold_eval_acc_hist.append(epoch_acc)\n",
        "                    fold_eval_loss_hist.append(epoch_loss)\n",
        "                else:\n",
        "                    fold_train_acc_hist.append(epoch_acc)\n",
        "                    fold_train_loss_hist.append(epoch_loss)\n",
        "\n",
        "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "                # If accuray of evaluation set increased, save the model as new best\n",
        "                if phase == 'val':\n",
        "                    if epoch_acc > fold_best_acc:\n",
        "                        fold_best_acc = epoch_acc\n",
        "                    if epoch_acc > best_acc:\n",
        "                        best_acc = epoch_acc\n",
        "                        best_model_weights = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            epoch_time_elapsed = time.time() - epoch_start_time\n",
        "            print('Epoch complete in {:.0f}m {:.0f}s'.format(epoch_time_elapsed // 60, epoch_time_elapsed % 60))    \n",
        "            print()\n",
        "\n",
        "        # reset model weights\n",
        "        model.load_state_dict(untrained_model_weights)\n",
        "        \n",
        "        time_elapsed = time.time() - fold_start_time\n",
        "        print('Fold {} Training complete in {:.0f}m {:.0f}s'.format(current_fold+1, time_elapsed // 60, time_elapsed % 60))\n",
        "        print('Fold {} Best val Acc: {:4f}'.format(current_fold+1, fold_best_acc))\n",
        "\n",
        "        train_acc_hist.append(fold_train_acc_hist)\n",
        "        train_loss_hist.append(fold_train_loss_hist)\n",
        "        eval_acc_hist.append(fold_eval_acc_hist)\n",
        "        eval_loss_hist.append(fold_eval_loss_hist)\n",
        "\n",
        "    print()\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "    # Get average curves\n",
        "    avg_train_acc = []\n",
        "    avg_train_loss = []\n",
        "    avg_eval_acc = []\n",
        "    avg_eval_loss= []\n",
        "    for epoch in range(epochs):\n",
        "        train_acc = 0.0\n",
        "        train_loss = 0.0\n",
        "        eval_acc = 0.0\n",
        "        eval_loss = 0.0\n",
        "        for fold in range(k):\n",
        "            train_acc += train_acc_hist[fold][epoch]\n",
        "            train_loss += train_loss_hist[fold][epoch]\n",
        "            eval_acc += eval_acc_hist[fold][epoch]\n",
        "            eval_loss += eval_loss_hist[fold][epoch]\n",
        "        avg_train_acc.append(train_acc/k)\n",
        "        avg_train_loss.append(train_loss/k)\n",
        "        avg_eval_acc.append(eval_acc/k)\n",
        "        avg_eval_loss.append(eval_loss/k)\n",
        "\n",
        "\n",
        "    # Plot graphs\n",
        "    if plot_acc:\n",
        "        fig, ax = plt.subplots()      \n",
        "        ax.plot(avg_train_acc, 'r', label=\"Average training acurracy\")\n",
        "        ax.plot(avg_eval_acc, 'b', label=\"Average evaluation accuracy\")\n",
        "        ax.set(xlabel=\"Epoch\", ylabel=\"Accuracy\", title=\"Traning Accuracy\")\n",
        "        ax.legend()\n",
        "        plt.show()\n",
        "    \n",
        "    if plot_loss:\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.plot(avg_train_loss, 'r', label=\"Average training loss\")\n",
        "        ax.plot(avg_eval_loss, 'b', label=\"Average evaluation loss\")\n",
        "        ax.set(xlabel=\"Epoch\", ylabel=\"Accuracy\", title=\"Traning Loss\")\n",
        "        ax.legend()\n",
        "        plt.show()\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_weights)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDxoZadG3LAO"
      },
      "source": [
        "Código que faz o tratamento do Dataset\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiAqf03-28fd"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#import FileHandling\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    \"\"\"Image dataset\"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, root_dir, class_count, transform=None, loadToGpu=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with all images names and classes.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            class_count(int): Amount of classes in the dataset\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "            loadToGpu (bool): If should load image data to GPU, in case of availability\n",
        "\n",
        "        Notes:\n",
        "            Classes are expected to be sequential numeric ints to make possible to emulate the output expected in form of an array.\n",
        "            Csv files with the listing ust not contain headers and each entry must be filename,class separated by a line break\n",
        "        \"\"\"\n",
        "        self.images = pd.read_csv(csv_file, header=None)\n",
        "        self.class_count = class_count\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.loadToGpu = loadToGpu\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, ind:int):\n",
        "        if torch.is_tensor(ind):\n",
        "            ind = ind.tolist()\n",
        "        #print(\"Indice: \", ind)\n",
        "        #if ind >= 1: #qualquer coisa tirar isso daqui\n",
        "        print(ind)\n",
        "        print(self.images.iloc[ind, 0])\n",
        "        img_path = os.path.join(self.root_dir,\n",
        "                                self.images.iloc[ind, 0])\n",
        "        #print(img_path)\n",
        "          \n",
        "        #image = FileHandling.readImage(img_path).convert('RGB')\n",
        "        image = readImage(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Transfer inputs to GPU if available\n",
        "        if self.loadToGpu and torch.cuda.is_available():\n",
        "            image = image.cuda()\n",
        "\n",
        "        return image\n",
        "\n",
        "    def getFilename(self, ind:int):\n",
        "        \"\"\"Get file name from image at given index.\n",
        "        Args:\n",
        "            ind(int): Image index\"\"\"\n",
        "        return self.images.iloc[ind, 0]\n",
        "\n",
        "    def getClass(self, ind:int):\n",
        "        \"\"\"Get class number from image at given index.\n",
        "        Args:\n",
        "            ind(int): Image index\n",
        "        \"\"\"\n",
        "        return self.images.iloc[ind, 1]\n",
        "\n",
        "    def getExpected(self, ind:int):\n",
        "        \"\"\"Get expected output from a network of image at given index.\n",
        "\n",
        "        Args:\n",
        "            ind(int): Image index\n",
        "        Output:\n",
        "            Tensor with size ([class_count]), filled with zeros except to the index that matches the image class\n",
        "        \"\"\"\n",
        "        #if ind >= 1: #qualquer coisa tirar isso daq\n",
        "        aux = np.zeros(self.class_count)\n",
        "        classInd = self.getClass(ind)\n",
        "        aux[int(classInd)] = 1 #converter para inteiro pois está lendo o classInd como string\n",
        "        return torch.tensor(aux, dtype=torch.float)\n",
        "\n",
        "    def getChannelsMeanAndStd(self):\n",
        "        \"\"\"Get means and standard deviations for each channel of the entire dataset.\n",
        "                \n",
        "        IMPORTANT: \n",
        "            Dataset content must be a Tensor ou have a transform that converts it's contet to Tensor type for this to work\n",
        "        \n",
        "        Output:\n",
        "            means(list), std(list): lists with calculated means and standard deviations for each channel in the whole dataset \n",
        "        \"\"\"\n",
        "        R_means = torch.zeros(len(self))\n",
        "        G_means = torch.zeros(len(self))\n",
        "        B_means = torch.zeros(len(self))\n",
        "        R_stds = torch.zeros(len(self))\n",
        "        G_stds = torch.zeros(len(self))\n",
        "        B_stds = torch.zeros(len(self))\n",
        "\n",
        "        for img in range(len(self)):\n",
        "            R_means[img] = torch.mean(self[img][0])\n",
        "            G_means[img] = torch.mean(self[img][1])\n",
        "            B_means[img] = torch.mean(self[img][2])\n",
        "            R_stds[img] = torch.mean(self[img][0])\n",
        "            G_stds[img] = torch.mean(self[img][1])\n",
        "            B_stds[img] = torch.mean(self[img][2])\n",
        "\n",
        "        R_mean = float(torch.mean(R_means))\n",
        "        G_mean = float(torch.mean(G_means))\n",
        "        B_mean = float(torch.mean(B_means))\n",
        "        R_std = float(torch.std(R_stds))\n",
        "        G_std = float(torch.std(G_stds))\n",
        "        B_std = float(torch.std(B_stds))\n",
        "\n",
        "        return [R_mean, G_mean, B_mean], [R_std, G_std, B_std]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB_xp8XS3TuU"
      },
      "source": [
        "Class Activation Maps:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2sESD7glA9J"
      },
      "source": [
        "import io\n",
        "from PIL import Image\n",
        "from torchvision import models, transforms\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import cv2\n",
        "import json\n",
        "from matplotlib import pyplot as plt\n",
        "from os import listdir\n",
        "\n",
        "#Alterar o nome do arquivo CSV e da pasta com as imagens se necessário\n",
        "#data = ImageDataset(\"csv_path\", \"images_folder_path\", 2, transform=trans)\n",
        "#benigno = ['/content/benigno/' + file for file in listdir('benigno')]\n",
        "#maligno = ['/content/maligno/' + file for file in listdir('maligno')]\n",
        "#images = benigno + maligno\n",
        "#images_csv = createFolderContentCsv('/content/Dataset/', 'images_csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e3e71dcdf3ef4f91b03e8e044cbc2cd6",
            "5ae6441081164e079b5e6b7a0216e06d",
            "ddcaee968e9a44288500d495dc9a7d0d",
            "d880c88ef4c84e21a3b656fa8280114e",
            "abe42a0d4aa04757922e48f8a6e91767",
            "a2a8e57966a34efc872a8abcbfe745fe",
            "9bbfad5b064d4b6bb6faaecbbeb9ee8f",
            "c35ee13d3d254b3180a6daed4486e47c",
            "22a89fd4a8e64cbeab50fc580bead0cd",
            "11c0706a0a7448f19761a678ef83b0e9",
            "b69f9f10bab645fa89145c6e5270c6c5"
          ]
        },
        "id": "JMxfdwNA472X",
        "outputId": "ae4a9b21-bcca-4998-e7e4-d3af7742ace3"
      },
      "source": [
        "# simple implementation of CAM in PyTorch for the networks such as ResNet, DenseNet, SqueezeNet, Inception\n",
        "# last update by BZ, June 30, 2021\n",
        "\n",
        "import io\n",
        "from PIL import Image\n",
        "from torchvision import models, transforms\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import cv2\n",
        "import json\n",
        "from matplotlib import pyplot as plt\n",
        "from os import listdir\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Load model\n",
        "net = models.resnet50(pretrained=True)\n",
        "finalconv_name = 'layer4'\n",
        "\n",
        "# 2. Freeze the training for all layers\n",
        "# Obs. This step only applies for transfer learning, if it's not your case just ignore it\n",
        "for param in net.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 3. Update output to match number of classes\n",
        "num_feats = net.fc.in_features\n",
        "net.fc = nn.Linear(num_feats, 2)\n",
        "\n",
        "# 4. Create transforms for the data\n",
        "# Obs. Normalization is encouraged if using a pretrained model, the values correspond to the\n",
        "# ImageNet dataset mean and standard deviations of each color channel. The pretraining was applied\n",
        "# using this values, but hey can be changed to values that best suits your case. \n",
        "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "# 5. Create dataset. This type can be found in the file Dataset.py of this package \n",
        "# and gets the path to a csv with the list of the images file names and the base path to the folder of the\n",
        "# images. If you don't have the csv already, you can use the 'createFolderContentCsv' function\n",
        "# from the file FileHandling.py. \n",
        "benigno = ['/content/Dataset/benigno/' + file for file in listdir('Dataset/benigno')]\n",
        "maligno = ['/content/Dataset/maligno/' + file for file in listdir('Dataset/maligno')]\n",
        "images = benigno + maligno\n",
        "#images = ['/content/Dataset/' + file for file in listdir('Dataset')]\n",
        "#data = ImageDataset('/content/Dataset/images_csv.csv', \"Dataset\", 2, transform=trans)\n",
        "#images.remove('/content/Dataset/benigno/.ipynb_checkpoints')\n",
        "\n",
        "classif = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]\n",
        "\n",
        "database = pd.DataFrame({'nome': images, 'classificacao': classif})\n",
        "\n",
        "database.to_csv('database.csv', header = False, index=False)\n",
        "\n",
        "#data = ImageDataset(\"/content/sample_data/dataset/csv_file.csv\", \"/content/sample_data/dataset\", 2, transform=trans)\n",
        "data = ImageDataset(\"/content/database.csv\", \"/content\", 2, transform=trans)\n",
        "\n",
        "# input image\n",
        "#LABELS_file = '/content/imagenet-simple-labels.json'\n",
        "#image_file = '/content/dataset/dobermann.png'\n",
        "\n",
        "# 6. Specify error and optimization functions \n",
        "crit = nn.MSELoss()\n",
        "opt = optim.SGD(net.parameters(), lr=0.001)\n",
        "\n",
        "# 7. Call the training function\n",
        "#trainedModel = cnn.trainCrossValidation(net,data,5,crit,opt,50, plotAcc = True)\n",
        "trainedModel = trainCrossValidation(net,data,5,crit,opt,50,True)\n",
        "#net.eval()\n",
        "trainedModel.eval()\n",
        "\n",
        "#networks such as googlenet, resnet, densenet already use global average pooling at the end, so CAM could be used directly.\n",
        "#Rede neural escolhida: ResNet-50\n",
        "#net = models.resnet50(pretrained=True)\n",
        "#finalconv_name = 'layer4'\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3e71dcdf3ef4f91b03e8e044cbc2cd6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n",
            "/content/Dataset/maligno/maligno (14).tif\n",
            "33\n",
            "/content/Dataset/maligno/maligno (13).tif\n",
            "1\n",
            "/content/Dataset/benigno/benigno (1).tif\n",
            "15\n",
            "/content/Dataset/benigno/benigno (14).tif\n",
            "29\n",
            "/content/Dataset/maligno/maligno (17).tif\n",
            "18\n",
            "/content/Dataset/benigno/benigno (7).tif\n",
            "12\n",
            "/content/Dataset/benigno/benigno (6).tif\n",
            "34\n",
            "/content/Dataset/maligno/maligno (2).tif\n",
            "35\n",
            "/content/Dataset/maligno/maligno (6).tif\n",
            "28\n",
            "/content/Dataset/maligno/maligno (9).tif\n",
            "37\n",
            "/content/Dataset/maligno/maligno (11).tif\n",
            "8\n",
            "/content/Dataset/benigno/benigno (20).tif\n",
            "21\n",
            "/content/Dataset/maligno/maligno (18).tif\n",
            "0\n",
            "/content/Dataset/benigno/benigno (10).tif\n",
            "27\n",
            "/content/Dataset/maligno/maligno (1).tif\n",
            "4\n",
            "/content/Dataset/benigno/benigno (9).tif\n",
            "16\n",
            "/content/Dataset/benigno/benigno (13).tif\n",
            "10\n",
            "/content/Dataset/benigno/benigno (18).tif\n",
            "26\n",
            "/content/Dataset/maligno/maligno (4).tif\n",
            "24\n",
            "/content/Dataset/maligno/maligno (3).tif\n",
            "11\n",
            "/content/Dataset/benigno/benigno (11).tif\n",
            "3\n",
            "/content/Dataset/benigno/benigno (5).tif\n",
            "13\n",
            "/content/Dataset/benigno/benigno (3).tif\n",
            "14\n",
            "/content/Dataset/benigno/benigno (17).tif\n",
            "7\n",
            "/content/Dataset/benigno/benigno (15).tif\n",
            "32\n",
            "/content/Dataset/maligno/maligno (10).tif\n",
            "25\n",
            "/content/Dataset/maligno/maligno (19).tif\n",
            "5\n",
            "/content/Dataset/benigno/benigno (8).tif\n",
            "31\n",
            "/content/Dataset/maligno/maligno (12).tif\n",
            "38\n",
            "/content/Dataset/maligno/maligno (7).tif\n",
            "17\n",
            "/content/Dataset/benigno/benigno (4).tif\n",
            "30\n",
            "/content/Dataset/maligno/maligno (8).tif\n",
            "9\n",
            "/content/Dataset/benigno/benigno (16).tif\n",
            "39\n",
            "/content/Dataset/maligno/maligno (20).tif\n",
            "36\n",
            "/content/Dataset/maligno/maligno (16).tif\n",
            "20\n",
            "/content/Dataset/maligno/maligno (15).tif\n",
            "6\n",
            "/content/Dataset/benigno/benigno (12).tif\n",
            "23\n",
            "/content/Dataset/maligno/maligno (5).tif\n",
            "19\n",
            "/content/Dataset/benigno/benigno (19).tif\n",
            "2\n",
            "/content/Dataset/benigno/benigno (2).tif\n",
            "----------\n",
            "Fold 1/5 - Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.0113 Acc: 0.5625\n",
            "val Loss: 0.0356 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 2/50\n",
            "train Loss: 0.0096 Acc: 0.5938\n",
            "val Loss: 0.0340 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 3/50\n",
            "train Loss: 0.0088 Acc: 0.6250\n",
            "val Loss: 0.0329 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 4/50\n",
            "train Loss: 0.0084 Acc: 0.7188\n",
            "val Loss: 0.0315 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 5/50\n",
            "train Loss: 0.0081 Acc: 0.7188\n",
            "val Loss: 0.0303 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 6/50\n",
            "train Loss: 0.0078 Acc: 0.7500\n",
            "val Loss: 0.0298 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 7/50\n",
            "train Loss: 0.0076 Acc: 0.7500\n",
            "val Loss: 0.0296 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 8/50\n",
            "train Loss: 0.0073 Acc: 0.8125\n",
            "val Loss: 0.0294 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 9/50\n",
            "train Loss: 0.0071 Acc: 0.8125\n",
            "val Loss: 0.0291 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 10/50\n",
            "train Loss: 0.0069 Acc: 0.8125\n",
            "val Loss: 0.0289 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 11/50\n",
            "train Loss: 0.0067 Acc: 0.8438\n",
            "val Loss: 0.0290 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 12/50\n",
            "train Loss: 0.0065 Acc: 0.8438\n",
            "val Loss: 0.0292 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 13/50\n",
            "train Loss: 0.0063 Acc: 0.8438\n",
            "val Loss: 0.0292 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 14/50\n",
            "train Loss: 0.0061 Acc: 0.8438\n",
            "val Loss: 0.0292 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 15/50\n",
            "train Loss: 0.0059 Acc: 0.8438\n",
            "val Loss: 0.0294 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 16/50\n",
            "train Loss: 0.0057 Acc: 0.8438\n",
            "val Loss: 0.0297 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 17/50\n",
            "train Loss: 0.0056 Acc: 0.8750\n",
            "val Loss: 0.0304 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 18/50\n",
            "train Loss: 0.0054 Acc: 0.8750\n",
            "val Loss: 0.0310 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 19/50\n",
            "train Loss: 0.0053 Acc: 0.8750\n",
            "val Loss: 0.0314 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 20/50\n",
            "train Loss: 0.0051 Acc: 0.8750\n",
            "val Loss: 0.0316 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 21/50\n",
            "train Loss: 0.0050 Acc: 0.8750\n",
            "val Loss: 0.0316 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 22/50\n",
            "train Loss: 0.0048 Acc: 0.8750\n",
            "val Loss: 0.0316 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 23/50\n",
            "train Loss: 0.0047 Acc: 0.8750\n",
            "val Loss: 0.0315 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 24/50\n",
            "train Loss: 0.0045 Acc: 0.8750\n",
            "val Loss: 0.0314 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 25/50\n",
            "train Loss: 0.0044 Acc: 0.8750\n",
            "val Loss: 0.0314 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 26/50\n",
            "train Loss: 0.0043 Acc: 0.8750\n",
            "val Loss: 0.0314 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 27/50\n",
            "train Loss: 0.0042 Acc: 0.8750\n",
            "val Loss: 0.0314 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 28/50\n",
            "train Loss: 0.0041 Acc: 0.8750\n",
            "val Loss: 0.0314 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 29/50\n",
            "train Loss: 0.0040 Acc: 0.8750\n",
            "val Loss: 0.0314 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 30/50\n",
            "train Loss: 0.0038 Acc: 0.9062\n",
            "val Loss: 0.0313 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 31/50\n",
            "train Loss: 0.0037 Acc: 0.9062\n",
            "val Loss: 0.0313 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 32/50\n",
            "train Loss: 0.0036 Acc: 0.9062\n",
            "val Loss: 0.0313 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 33/50\n",
            "train Loss: 0.0036 Acc: 0.9062\n",
            "val Loss: 0.0312 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 34/50\n",
            "train Loss: 0.0035 Acc: 0.9062\n",
            "val Loss: 0.0312 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 35/50\n",
            "train Loss: 0.0034 Acc: 0.9062\n",
            "val Loss: 0.0311 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 36/50\n",
            "train Loss: 0.0033 Acc: 0.9062\n",
            "val Loss: 0.0311 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 37/50\n",
            "train Loss: 0.0032 Acc: 0.9062\n",
            "val Loss: 0.0310 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 38/50\n",
            "train Loss: 0.0031 Acc: 0.9062\n",
            "val Loss: 0.0309 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 39/50\n",
            "train Loss: 0.0030 Acc: 0.9062\n",
            "val Loss: 0.0309 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 40/50\n",
            "train Loss: 0.0030 Acc: 0.9062\n",
            "val Loss: 0.0308 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 41/50\n",
            "train Loss: 0.0029 Acc: 0.9375\n",
            "val Loss: 0.0307 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 42/50\n",
            "train Loss: 0.0028 Acc: 0.9375\n",
            "val Loss: 0.0307 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 43/50\n",
            "train Loss: 0.0027 Acc: 0.9375\n",
            "val Loss: 0.0306 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 44/50\n",
            "train Loss: 0.0027 Acc: 0.9375\n",
            "val Loss: 0.0305 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 45/50\n",
            "train Loss: 0.0026 Acc: 0.9375\n",
            "val Loss: 0.0305 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 46/50\n",
            "train Loss: 0.0026 Acc: 0.9375\n",
            "val Loss: 0.0304 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 47/50\n",
            "train Loss: 0.0025 Acc: 0.9375\n",
            "val Loss: 0.0303 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 48/50\n",
            "train Loss: 0.0024 Acc: 0.9375\n",
            "val Loss: 0.0303 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 49/50\n",
            "train Loss: 0.0024 Acc: 0.9688\n",
            "val Loss: 0.0302 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 1/5 - Epoch 50/50\n",
            "train Loss: 0.0023 Acc: 0.9688\n",
            "val Loss: 0.0301 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "Fold 1 Training complete in 3m 13s\n",
            "Fold 1 Best val Acc: 0.625000\n",
            "9\n",
            "/content/Dataset/benigno/benigno (16).tif\n",
            "39\n",
            "/content/Dataset/maligno/maligno (20).tif\n",
            "36\n",
            "/content/Dataset/maligno/maligno (16).tif\n",
            "20\n",
            "/content/Dataset/maligno/maligno (15).tif\n",
            "6\n",
            "/content/Dataset/benigno/benigno (12).tif\n",
            "23\n",
            "/content/Dataset/maligno/maligno (5).tif\n",
            "19\n",
            "/content/Dataset/benigno/benigno (19).tif\n",
            "2\n",
            "/content/Dataset/benigno/benigno (2).tif\n",
            "35\n",
            "/content/Dataset/maligno/maligno (6).tif\n",
            "28\n",
            "/content/Dataset/maligno/maligno (9).tif\n",
            "37\n",
            "/content/Dataset/maligno/maligno (11).tif\n",
            "8\n",
            "/content/Dataset/benigno/benigno (20).tif\n",
            "21\n",
            "/content/Dataset/maligno/maligno (18).tif\n",
            "0\n",
            "/content/Dataset/benigno/benigno (10).tif\n",
            "27\n",
            "/content/Dataset/maligno/maligno (1).tif\n",
            "4\n",
            "/content/Dataset/benigno/benigno (9).tif\n",
            "16\n",
            "/content/Dataset/benigno/benigno (13).tif\n",
            "10\n",
            "/content/Dataset/benigno/benigno (18).tif\n",
            "26\n",
            "/content/Dataset/maligno/maligno (4).tif\n",
            "24\n",
            "/content/Dataset/maligno/maligno (3).tif\n",
            "11\n",
            "/content/Dataset/benigno/benigno (11).tif\n",
            "3\n",
            "/content/Dataset/benigno/benigno (5).tif\n",
            "13\n",
            "/content/Dataset/benigno/benigno (3).tif\n",
            "14\n",
            "/content/Dataset/benigno/benigno (17).tif\n",
            "7\n",
            "/content/Dataset/benigno/benigno (15).tif\n",
            "32\n",
            "/content/Dataset/maligno/maligno (10).tif\n",
            "25\n",
            "/content/Dataset/maligno/maligno (19).tif\n",
            "5\n",
            "/content/Dataset/benigno/benigno (8).tif\n",
            "31\n",
            "/content/Dataset/maligno/maligno (12).tif\n",
            "38\n",
            "/content/Dataset/maligno/maligno (7).tif\n",
            "17\n",
            "/content/Dataset/benigno/benigno (4).tif\n",
            "30\n",
            "/content/Dataset/maligno/maligno (8).tif\n",
            "22\n",
            "/content/Dataset/maligno/maligno (14).tif\n",
            "33\n",
            "/content/Dataset/maligno/maligno (13).tif\n",
            "1\n",
            "/content/Dataset/benigno/benigno (1).tif\n",
            "15\n",
            "/content/Dataset/benigno/benigno (14).tif\n",
            "29\n",
            "/content/Dataset/maligno/maligno (17).tif\n",
            "18\n",
            "/content/Dataset/benigno/benigno (7).tif\n",
            "12\n",
            "/content/Dataset/benigno/benigno (6).tif\n",
            "34\n",
            "/content/Dataset/maligno/maligno (2).tif\n",
            "----------\n",
            "Fold 2/5 - Epoch 1/50\n",
            "train Loss: 0.0106 Acc: 0.5625\n",
            "val Loss: 0.0426 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 2/50\n",
            "train Loss: 0.0089 Acc: 0.5938\n",
            "val Loss: 0.0422 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 3/50\n",
            "train Loss: 0.0082 Acc: 0.6562\n",
            "val Loss: 0.0413 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 4/50\n",
            "train Loss: 0.0079 Acc: 0.6562\n",
            "val Loss: 0.0402 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 5/50\n",
            "train Loss: 0.0076 Acc: 0.6562\n",
            "val Loss: 0.0389 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 6/50\n",
            "train Loss: 0.0074 Acc: 0.6562\n",
            "val Loss: 0.0380 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 7/50\n",
            "train Loss: 0.0072 Acc: 0.6562\n",
            "val Loss: 0.0376 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 8/50\n",
            "train Loss: 0.0070 Acc: 0.7188\n",
            "val Loss: 0.0375 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 9/50\n",
            "train Loss: 0.0068 Acc: 0.7812\n",
            "val Loss: 0.0379 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 10/50\n",
            "train Loss: 0.0066 Acc: 0.7812\n",
            "val Loss: 0.0387 Acc: 0.3750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 11/50\n",
            "train Loss: 0.0064 Acc: 0.7812\n",
            "val Loss: 0.0396 Acc: 0.3750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 12/50\n",
            "train Loss: 0.0063 Acc: 0.7812\n",
            "val Loss: 0.0399 Acc: 0.3750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 13/50\n",
            "train Loss: 0.0061 Acc: 0.7812\n",
            "val Loss: 0.0398 Acc: 0.3750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 14/50\n",
            "train Loss: 0.0059 Acc: 0.8125\n",
            "val Loss: 0.0393 Acc: 0.3750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 15/50\n",
            "train Loss: 0.0058 Acc: 0.8438\n",
            "val Loss: 0.0381 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 16/50\n",
            "train Loss: 0.0056 Acc: 0.8438\n",
            "val Loss: 0.0373 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 17/50\n",
            "train Loss: 0.0055 Acc: 0.8438\n",
            "val Loss: 0.0364 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 18/50\n",
            "train Loss: 0.0054 Acc: 0.8438\n",
            "val Loss: 0.0358 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 19/50\n",
            "train Loss: 0.0052 Acc: 0.8438\n",
            "val Loss: 0.0352 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 20/50\n",
            "train Loss: 0.0051 Acc: 0.8438\n",
            "val Loss: 0.0348 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 21/50\n",
            "train Loss: 0.0050 Acc: 0.8438\n",
            "val Loss: 0.0345 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 22/50\n",
            "train Loss: 0.0048 Acc: 0.8750\n",
            "val Loss: 0.0345 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 23/50\n",
            "train Loss: 0.0047 Acc: 0.8750\n",
            "val Loss: 0.0350 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 24/50\n",
            "train Loss: 0.0046 Acc: 0.8750\n",
            "val Loss: 0.0358 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 25/50\n",
            "train Loss: 0.0045 Acc: 0.8750\n",
            "val Loss: 0.0363 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 26/50\n",
            "train Loss: 0.0044 Acc: 0.8750\n",
            "val Loss: 0.0365 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 27/50\n",
            "train Loss: 0.0043 Acc: 0.8750\n",
            "val Loss: 0.0367 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 28/50\n",
            "train Loss: 0.0042 Acc: 0.8750\n",
            "val Loss: 0.0369 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 29/50\n",
            "train Loss: 0.0041 Acc: 0.9062\n",
            "val Loss: 0.0370 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 30/50\n",
            "train Loss: 0.0040 Acc: 0.9062\n",
            "val Loss: 0.0369 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 31/50\n",
            "train Loss: 0.0039 Acc: 0.9062\n",
            "val Loss: 0.0368 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 32/50\n",
            "train Loss: 0.0038 Acc: 0.9062\n",
            "val Loss: 0.0367 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 33/50\n",
            "train Loss: 0.0037 Acc: 0.9062\n",
            "val Loss: 0.0365 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 34/50\n",
            "train Loss: 0.0036 Acc: 0.9062\n",
            "val Loss: 0.0364 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 35/50\n",
            "train Loss: 0.0035 Acc: 0.9062\n",
            "val Loss: 0.0362 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 36/50\n",
            "train Loss: 0.0034 Acc: 0.9062\n",
            "val Loss: 0.0360 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 37/50\n",
            "train Loss: 0.0033 Acc: 0.9062\n",
            "val Loss: 0.0358 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 38/50\n",
            "train Loss: 0.0033 Acc: 0.9062\n",
            "val Loss: 0.0356 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 39/50\n",
            "train Loss: 0.0032 Acc: 0.9062\n",
            "val Loss: 0.0355 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 40/50\n",
            "train Loss: 0.0031 Acc: 0.9062\n",
            "val Loss: 0.0354 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 41/50\n",
            "train Loss: 0.0030 Acc: 0.9062\n",
            "val Loss: 0.0352 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 42/50\n",
            "train Loss: 0.0030 Acc: 0.9062\n",
            "val Loss: 0.0351 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 43/50\n",
            "train Loss: 0.0029 Acc: 0.9062\n",
            "val Loss: 0.0350 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 44/50\n",
            "train Loss: 0.0028 Acc: 0.9375\n",
            "val Loss: 0.0348 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 45/50\n",
            "train Loss: 0.0028 Acc: 0.9375\n",
            "val Loss: 0.0347 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 46/50\n",
            "train Loss: 0.0027 Acc: 0.9688\n",
            "val Loss: 0.0346 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 47/50\n",
            "train Loss: 0.0027 Acc: 0.9688\n",
            "val Loss: 0.0345 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 48/50\n",
            "train Loss: 0.0026 Acc: 0.9688\n",
            "val Loss: 0.0343 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 49/50\n",
            "train Loss: 0.0025 Acc: 1.0000\n",
            "val Loss: 0.0342 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 2/5 - Epoch 50/50\n",
            "train Loss: 0.0025 Acc: 1.0000\n",
            "val Loss: 0.0341 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "Fold 2 Training complete in 3m 12s\n",
            "Fold 2 Best val Acc: 0.625000\n",
            "9\n",
            "/content/Dataset/benigno/benigno (16).tif\n",
            "39\n",
            "/content/Dataset/maligno/maligno (20).tif\n",
            "36\n",
            "/content/Dataset/maligno/maligno (16).tif\n",
            "20\n",
            "/content/Dataset/maligno/maligno (15).tif\n",
            "6\n",
            "/content/Dataset/benigno/benigno (12).tif\n",
            "23\n",
            "/content/Dataset/maligno/maligno (5).tif\n",
            "19\n",
            "/content/Dataset/benigno/benigno (19).tif\n",
            "2\n",
            "/content/Dataset/benigno/benigno (2).tif\n",
            "22\n",
            "/content/Dataset/maligno/maligno (14).tif\n",
            "33\n",
            "/content/Dataset/maligno/maligno (13).tif\n",
            "1\n",
            "/content/Dataset/benigno/benigno (1).tif\n",
            "15\n",
            "/content/Dataset/benigno/benigno (14).tif\n",
            "29\n",
            "/content/Dataset/maligno/maligno (17).tif\n",
            "18\n",
            "/content/Dataset/benigno/benigno (7).tif\n",
            "12\n",
            "/content/Dataset/benigno/benigno (6).tif\n",
            "34\n",
            "/content/Dataset/maligno/maligno (2).tif\n",
            "16\n",
            "/content/Dataset/benigno/benigno (13).tif\n",
            "10\n",
            "/content/Dataset/benigno/benigno (18).tif\n",
            "26\n",
            "/content/Dataset/maligno/maligno (4).tif\n",
            "24\n",
            "/content/Dataset/maligno/maligno (3).tif\n",
            "11\n",
            "/content/Dataset/benigno/benigno (11).tif\n",
            "3\n",
            "/content/Dataset/benigno/benigno (5).tif\n",
            "13\n",
            "/content/Dataset/benigno/benigno (3).tif\n",
            "14\n",
            "/content/Dataset/benigno/benigno (17).tif\n",
            "7\n",
            "/content/Dataset/benigno/benigno (15).tif\n",
            "32\n",
            "/content/Dataset/maligno/maligno (10).tif\n",
            "25\n",
            "/content/Dataset/maligno/maligno (19).tif\n",
            "5\n",
            "/content/Dataset/benigno/benigno (8).tif\n",
            "31\n",
            "/content/Dataset/maligno/maligno (12).tif\n",
            "38\n",
            "/content/Dataset/maligno/maligno (7).tif\n",
            "17\n",
            "/content/Dataset/benigno/benigno (4).tif\n",
            "30\n",
            "/content/Dataset/maligno/maligno (8).tif\n",
            "35\n",
            "/content/Dataset/maligno/maligno (6).tif\n",
            "28\n",
            "/content/Dataset/maligno/maligno (9).tif\n",
            "37\n",
            "/content/Dataset/maligno/maligno (11).tif\n",
            "8\n",
            "/content/Dataset/benigno/benigno (20).tif\n",
            "21\n",
            "/content/Dataset/maligno/maligno (18).tif\n",
            "0\n",
            "/content/Dataset/benigno/benigno (10).tif\n",
            "27\n",
            "/content/Dataset/maligno/maligno (1).tif\n",
            "4\n",
            "/content/Dataset/benigno/benigno (9).tif\n",
            "----------\n",
            "Fold 3/5 - Epoch 1/50\n",
            "train Loss: 0.0110 Acc: 0.5000\n",
            "val Loss: 0.0385 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 2/50\n",
            "train Loss: 0.0093 Acc: 0.5625\n",
            "val Loss: 0.0390 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 3/50\n",
            "train Loss: 0.0086 Acc: 0.6250\n",
            "val Loss: 0.0391 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 4/50\n",
            "train Loss: 0.0082 Acc: 0.6250\n",
            "val Loss: 0.0383 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 5/50\n",
            "train Loss: 0.0079 Acc: 0.6562\n",
            "val Loss: 0.0371 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 6/50\n",
            "train Loss: 0.0077 Acc: 0.6562\n",
            "val Loss: 0.0354 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 7/50\n",
            "train Loss: 0.0074 Acc: 0.7188\n",
            "val Loss: 0.0343 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 8/50\n",
            "train Loss: 0.0072 Acc: 0.7500\n",
            "val Loss: 0.0345 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 9/50\n",
            "train Loss: 0.0070 Acc: 0.7812\n",
            "val Loss: 0.0348 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 10/50\n",
            "train Loss: 0.0068 Acc: 0.7812\n",
            "val Loss: 0.0352 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 11/50\n",
            "train Loss: 0.0067 Acc: 0.7812\n",
            "val Loss: 0.0350 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 12/50\n",
            "train Loss: 0.0065 Acc: 0.7812\n",
            "val Loss: 0.0347 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 13/50\n",
            "train Loss: 0.0063 Acc: 0.7812\n",
            "val Loss: 0.0340 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 14/50\n",
            "train Loss: 0.0061 Acc: 0.7812\n",
            "val Loss: 0.0328 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 15/50\n",
            "train Loss: 0.0060 Acc: 0.7812\n",
            "val Loss: 0.0316 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 16/50\n",
            "train Loss: 0.0058 Acc: 0.7812\n",
            "val Loss: 0.0309 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 17/50\n",
            "train Loss: 0.0056 Acc: 0.8125\n",
            "val Loss: 0.0304 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 18/50\n",
            "train Loss: 0.0055 Acc: 0.8125\n",
            "val Loss: 0.0298 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 19/50\n",
            "train Loss: 0.0053 Acc: 0.8125\n",
            "val Loss: 0.0293 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 20/50\n",
            "train Loss: 0.0052 Acc: 0.8125\n",
            "val Loss: 0.0286 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 21/50\n",
            "train Loss: 0.0051 Acc: 0.8125\n",
            "val Loss: 0.0280 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 22/50\n",
            "train Loss: 0.0049 Acc: 0.8125\n",
            "val Loss: 0.0273 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 23/50\n",
            "train Loss: 0.0048 Acc: 0.8125\n",
            "val Loss: 0.0268 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 24/50\n",
            "train Loss: 0.0047 Acc: 0.8438\n",
            "val Loss: 0.0263 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 25/50\n",
            "train Loss: 0.0046 Acc: 0.8438\n",
            "val Loss: 0.0260 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 26/50\n",
            "train Loss: 0.0044 Acc: 0.8750\n",
            "val Loss: 0.0257 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 27/50\n",
            "train Loss: 0.0043 Acc: 0.8750\n",
            "val Loss: 0.0254 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 28/50\n",
            "train Loss: 0.0042 Acc: 0.9062\n",
            "val Loss: 0.0252 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 29/50\n",
            "train Loss: 0.0041 Acc: 0.9375\n",
            "val Loss: 0.0248 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 30/50\n",
            "train Loss: 0.0040 Acc: 0.9375\n",
            "val Loss: 0.0245 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 31/50\n",
            "train Loss: 0.0039 Acc: 0.9375\n",
            "val Loss: 0.0242 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 32/50\n",
            "train Loss: 0.0038 Acc: 0.9375\n",
            "val Loss: 0.0239 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 33/50\n",
            "train Loss: 0.0037 Acc: 0.9688\n",
            "val Loss: 0.0237 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 34/50\n",
            "train Loss: 0.0036 Acc: 0.9688\n",
            "val Loss: 0.0234 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 35/50\n",
            "train Loss: 0.0035 Acc: 0.9688\n",
            "val Loss: 0.0232 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 36/50\n",
            "train Loss: 0.0034 Acc: 0.9688\n",
            "val Loss: 0.0229 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 37/50\n",
            "train Loss: 0.0034 Acc: 0.9688\n",
            "val Loss: 0.0227 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 38/50\n",
            "train Loss: 0.0033 Acc: 0.9688\n",
            "val Loss: 0.0226 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 39/50\n",
            "train Loss: 0.0032 Acc: 0.9688\n",
            "val Loss: 0.0224 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 40/50\n",
            "train Loss: 0.0031 Acc: 0.9688\n",
            "val Loss: 0.0222 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 41/50\n",
            "train Loss: 0.0030 Acc: 0.9688\n",
            "val Loss: 0.0220 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 42/50\n",
            "train Loss: 0.0030 Acc: 0.9688\n",
            "val Loss: 0.0218 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 43/50\n",
            "train Loss: 0.0029 Acc: 0.9688\n",
            "val Loss: 0.0217 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 44/50\n",
            "train Loss: 0.0028 Acc: 1.0000\n",
            "val Loss: 0.0215 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 45/50\n",
            "train Loss: 0.0028 Acc: 1.0000\n",
            "val Loss: 0.0213 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 46/50\n",
            "train Loss: 0.0027 Acc: 1.0000\n",
            "val Loss: 0.0211 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 47/50\n",
            "train Loss: 0.0026 Acc: 1.0000\n",
            "val Loss: 0.0209 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 48/50\n",
            "train Loss: 0.0026 Acc: 1.0000\n",
            "val Loss: 0.0207 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 49/50\n",
            "train Loss: 0.0025 Acc: 1.0000\n",
            "val Loss: 0.0205 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 3/5 - Epoch 50/50\n",
            "train Loss: 0.0025 Acc: 1.0000\n",
            "val Loss: 0.0204 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "Fold 3 Training complete in 3m 12s\n",
            "Fold 3 Best val Acc: 0.875000\n",
            "9\n",
            "/content/Dataset/benigno/benigno (16).tif\n",
            "39\n",
            "/content/Dataset/maligno/maligno (20).tif\n",
            "36\n",
            "/content/Dataset/maligno/maligno (16).tif\n",
            "20\n",
            "/content/Dataset/maligno/maligno (15).tif\n",
            "6\n",
            "/content/Dataset/benigno/benigno (12).tif\n",
            "23\n",
            "/content/Dataset/maligno/maligno (5).tif\n",
            "19\n",
            "/content/Dataset/benigno/benigno (19).tif\n",
            "2\n",
            "/content/Dataset/benigno/benigno (2).tif\n",
            "22\n",
            "/content/Dataset/maligno/maligno (14).tif\n",
            "33\n",
            "/content/Dataset/maligno/maligno (13).tif\n",
            "1\n",
            "/content/Dataset/benigno/benigno (1).tif\n",
            "15\n",
            "/content/Dataset/benigno/benigno (14).tif\n",
            "29\n",
            "/content/Dataset/maligno/maligno (17).tif\n",
            "18\n",
            "/content/Dataset/benigno/benigno (7).tif\n",
            "12\n",
            "/content/Dataset/benigno/benigno (6).tif\n",
            "34\n",
            "/content/Dataset/maligno/maligno (2).tif\n",
            "35\n",
            "/content/Dataset/maligno/maligno (6).tif\n",
            "28\n",
            "/content/Dataset/maligno/maligno (9).tif\n",
            "37\n",
            "/content/Dataset/maligno/maligno (11).tif\n",
            "8\n",
            "/content/Dataset/benigno/benigno (20).tif\n",
            "21\n",
            "/content/Dataset/maligno/maligno (18).tif\n",
            "0\n",
            "/content/Dataset/benigno/benigno (10).tif\n",
            "27\n",
            "/content/Dataset/maligno/maligno (1).tif\n",
            "4\n",
            "/content/Dataset/benigno/benigno (9).tif\n",
            "7\n",
            "/content/Dataset/benigno/benigno (15).tif\n",
            "32\n",
            "/content/Dataset/maligno/maligno (10).tif\n",
            "25\n",
            "/content/Dataset/maligno/maligno (19).tif\n",
            "5\n",
            "/content/Dataset/benigno/benigno (8).tif\n",
            "31\n",
            "/content/Dataset/maligno/maligno (12).tif\n",
            "38\n",
            "/content/Dataset/maligno/maligno (7).tif\n",
            "17\n",
            "/content/Dataset/benigno/benigno (4).tif\n",
            "30\n",
            "/content/Dataset/maligno/maligno (8).tif\n",
            "16\n",
            "/content/Dataset/benigno/benigno (13).tif\n",
            "10\n",
            "/content/Dataset/benigno/benigno (18).tif\n",
            "26\n",
            "/content/Dataset/maligno/maligno (4).tif\n",
            "24\n",
            "/content/Dataset/maligno/maligno (3).tif\n",
            "11\n",
            "/content/Dataset/benigno/benigno (11).tif\n",
            "3\n",
            "/content/Dataset/benigno/benigno (5).tif\n",
            "13\n",
            "/content/Dataset/benigno/benigno (3).tif\n",
            "14\n",
            "/content/Dataset/benigno/benigno (17).tif\n",
            "----------\n",
            "Fold 4/5 - Epoch 1/50\n",
            "train Loss: 0.0114 Acc: 0.5625\n",
            "val Loss: 0.0320 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 2/50\n",
            "train Loss: 0.0095 Acc: 0.5625\n",
            "val Loss: 0.0335 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 3/50\n",
            "train Loss: 0.0088 Acc: 0.5625\n",
            "val Loss: 0.0359 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 4/50\n",
            "train Loss: 0.0084 Acc: 0.5938\n",
            "val Loss: 0.0379 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 5/50\n",
            "train Loss: 0.0081 Acc: 0.6250\n",
            "val Loss: 0.0390 Acc: 0.3750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 6/50\n",
            "train Loss: 0.0079 Acc: 0.6875\n",
            "val Loss: 0.0394 Acc: 0.3750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 7/50\n",
            "train Loss: 0.0076 Acc: 0.6875\n",
            "val Loss: 0.0395 Acc: 0.3750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 8/50\n",
            "train Loss: 0.0074 Acc: 0.7500\n",
            "val Loss: 0.0398 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 9/50\n",
            "train Loss: 0.0072 Acc: 0.7500\n",
            "val Loss: 0.0406 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 10/50\n",
            "train Loss: 0.0070 Acc: 0.7500\n",
            "val Loss: 0.0416 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 11/50\n",
            "train Loss: 0.0068 Acc: 0.7500\n",
            "val Loss: 0.0425 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 12/50\n",
            "train Loss: 0.0066 Acc: 0.7812\n",
            "val Loss: 0.0429 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 13/50\n",
            "train Loss: 0.0065 Acc: 0.7812\n",
            "val Loss: 0.0433 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 14/50\n",
            "train Loss: 0.0063 Acc: 0.7812\n",
            "val Loss: 0.0430 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 15/50\n",
            "train Loss: 0.0061 Acc: 0.8125\n",
            "val Loss: 0.0425 Acc: 0.5000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 16/50\n",
            "train Loss: 0.0059 Acc: 0.8125\n",
            "val Loss: 0.0416 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 17/50\n",
            "train Loss: 0.0058 Acc: 0.8125\n",
            "val Loss: 0.0406 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 18/50\n",
            "train Loss: 0.0056 Acc: 0.8438\n",
            "val Loss: 0.0397 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 19/50\n",
            "train Loss: 0.0055 Acc: 0.8438\n",
            "val Loss: 0.0391 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 20/50\n",
            "train Loss: 0.0053 Acc: 0.8438\n",
            "val Loss: 0.0383 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 21/50\n",
            "train Loss: 0.0052 Acc: 0.8438\n",
            "val Loss: 0.0375 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 22/50\n",
            "train Loss: 0.0051 Acc: 0.8438\n",
            "val Loss: 0.0366 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 23/50\n",
            "train Loss: 0.0049 Acc: 0.8438\n",
            "val Loss: 0.0359 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 24/50\n",
            "train Loss: 0.0048 Acc: 0.8438\n",
            "val Loss: 0.0353 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 25/50\n",
            "train Loss: 0.0047 Acc: 0.8750\n",
            "val Loss: 0.0347 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 26/50\n",
            "train Loss: 0.0046 Acc: 0.8750\n",
            "val Loss: 0.0342 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 27/50\n",
            "train Loss: 0.0044 Acc: 0.9062\n",
            "val Loss: 0.0339 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 28/50\n",
            "train Loss: 0.0043 Acc: 0.9062\n",
            "val Loss: 0.0337 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 29/50\n",
            "train Loss: 0.0042 Acc: 0.9062\n",
            "val Loss: 0.0336 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 30/50\n",
            "train Loss: 0.0041 Acc: 0.9062\n",
            "val Loss: 0.0335 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 31/50\n",
            "train Loss: 0.0040 Acc: 0.9375\n",
            "val Loss: 0.0334 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 32/50\n",
            "train Loss: 0.0039 Acc: 0.9375\n",
            "val Loss: 0.0333 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 33/50\n",
            "train Loss: 0.0038 Acc: 0.9375\n",
            "val Loss: 0.0332 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 34/50\n",
            "train Loss: 0.0037 Acc: 0.9375\n",
            "val Loss: 0.0331 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 35/50\n",
            "train Loss: 0.0036 Acc: 0.9375\n",
            "val Loss: 0.0329 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 36/50\n",
            "train Loss: 0.0035 Acc: 0.9375\n",
            "val Loss: 0.0328 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 37/50\n",
            "train Loss: 0.0034 Acc: 0.9375\n",
            "val Loss: 0.0326 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 38/50\n",
            "train Loss: 0.0034 Acc: 0.9375\n",
            "val Loss: 0.0325 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 39/50\n",
            "train Loss: 0.0033 Acc: 0.9375\n",
            "val Loss: 0.0323 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 40/50\n",
            "train Loss: 0.0032 Acc: 0.9688\n",
            "val Loss: 0.0322 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 41/50\n",
            "train Loss: 0.0031 Acc: 0.9688\n",
            "val Loss: 0.0321 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 42/50\n",
            "train Loss: 0.0030 Acc: 0.9688\n",
            "val Loss: 0.0320 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 43/50\n",
            "train Loss: 0.0030 Acc: 0.9688\n",
            "val Loss: 0.0319 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 44/50\n",
            "train Loss: 0.0029 Acc: 0.9688\n",
            "val Loss: 0.0318 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 45/50\n",
            "train Loss: 0.0028 Acc: 0.9688\n",
            "val Loss: 0.0317 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 46/50\n",
            "train Loss: 0.0028 Acc: 0.9688\n",
            "val Loss: 0.0316 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 47/50\n",
            "train Loss: 0.0027 Acc: 0.9688\n",
            "val Loss: 0.0315 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 48/50\n",
            "train Loss: 0.0026 Acc: 0.9688\n",
            "val Loss: 0.0315 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 49/50\n",
            "train Loss: 0.0026 Acc: 0.9688\n",
            "val Loss: 0.0314 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 4/5 - Epoch 50/50\n",
            "train Loss: 0.0025 Acc: 0.9688\n",
            "val Loss: 0.0314 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "Fold 4 Training complete in 3m 12s\n",
            "Fold 4 Best val Acc: 0.750000\n",
            "9\n",
            "/content/Dataset/benigno/benigno (16).tif\n",
            "39\n",
            "/content/Dataset/maligno/maligno (20).tif\n",
            "36\n",
            "/content/Dataset/maligno/maligno (16).tif\n",
            "20\n",
            "/content/Dataset/maligno/maligno (15).tif\n",
            "6\n",
            "/content/Dataset/benigno/benigno (12).tif\n",
            "23\n",
            "/content/Dataset/maligno/maligno (5).tif\n",
            "19\n",
            "/content/Dataset/benigno/benigno (19).tif\n",
            "2\n",
            "/content/Dataset/benigno/benigno (2).tif\n",
            "22\n",
            "/content/Dataset/maligno/maligno (14).tif\n",
            "33\n",
            "/content/Dataset/maligno/maligno (13).tif\n",
            "1\n",
            "/content/Dataset/benigno/benigno (1).tif\n",
            "15\n",
            "/content/Dataset/benigno/benigno (14).tif\n",
            "29\n",
            "/content/Dataset/maligno/maligno (17).tif\n",
            "18\n",
            "/content/Dataset/benigno/benigno (7).tif\n",
            "12\n",
            "/content/Dataset/benigno/benigno (6).tif\n",
            "34\n",
            "/content/Dataset/maligno/maligno (2).tif\n",
            "35\n",
            "/content/Dataset/maligno/maligno (6).tif\n",
            "28\n",
            "/content/Dataset/maligno/maligno (9).tif\n",
            "37\n",
            "/content/Dataset/maligno/maligno (11).tif\n",
            "8\n",
            "/content/Dataset/benigno/benigno (20).tif\n",
            "21\n",
            "/content/Dataset/maligno/maligno (18).tif\n",
            "0\n",
            "/content/Dataset/benigno/benigno (10).tif\n",
            "27\n",
            "/content/Dataset/maligno/maligno (1).tif\n",
            "4\n",
            "/content/Dataset/benigno/benigno (9).tif\n",
            "16\n",
            "/content/Dataset/benigno/benigno (13).tif\n",
            "10\n",
            "/content/Dataset/benigno/benigno (18).tif\n",
            "26\n",
            "/content/Dataset/maligno/maligno (4).tif\n",
            "24\n",
            "/content/Dataset/maligno/maligno (3).tif\n",
            "11\n",
            "/content/Dataset/benigno/benigno (11).tif\n",
            "3\n",
            "/content/Dataset/benigno/benigno (5).tif\n",
            "13\n",
            "/content/Dataset/benigno/benigno (3).tif\n",
            "14\n",
            "/content/Dataset/benigno/benigno (17).tif\n",
            "7\n",
            "/content/Dataset/benigno/benigno (15).tif\n",
            "32\n",
            "/content/Dataset/maligno/maligno (10).tif\n",
            "25\n",
            "/content/Dataset/maligno/maligno (19).tif\n",
            "5\n",
            "/content/Dataset/benigno/benigno (8).tif\n",
            "31\n",
            "/content/Dataset/maligno/maligno (12).tif\n",
            "38\n",
            "/content/Dataset/maligno/maligno (7).tif\n",
            "17\n",
            "/content/Dataset/benigno/benigno (4).tif\n",
            "30\n",
            "/content/Dataset/maligno/maligno (8).tif\n",
            "----------\n",
            "Fold 5/5 - Epoch 1/50\n",
            "train Loss: 0.0114 Acc: 0.5312\n",
            "val Loss: 0.0268 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 2/50\n",
            "train Loss: 0.0096 Acc: 0.5312\n",
            "val Loss: 0.0269 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 3/50\n",
            "train Loss: 0.0089 Acc: 0.5625\n",
            "val Loss: 0.0272 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 4/50\n",
            "train Loss: 0.0085 Acc: 0.5938\n",
            "val Loss: 0.0276 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 5/50\n",
            "train Loss: 0.0082 Acc: 0.5938\n",
            "val Loss: 0.0283 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 6/50\n",
            "train Loss: 0.0080 Acc: 0.6250\n",
            "val Loss: 0.0285 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 7/50\n",
            "train Loss: 0.0077 Acc: 0.6250\n",
            "val Loss: 0.0288 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 8/50\n",
            "train Loss: 0.0075 Acc: 0.6250\n",
            "val Loss: 0.0287 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 9/50\n",
            "train Loss: 0.0073 Acc: 0.6250\n",
            "val Loss: 0.0289 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 10/50\n",
            "train Loss: 0.0071 Acc: 0.6562\n",
            "val Loss: 0.0290 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 11/50\n",
            "train Loss: 0.0069 Acc: 0.6562\n",
            "val Loss: 0.0293 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 12/50\n",
            "train Loss: 0.0067 Acc: 0.6875\n",
            "val Loss: 0.0294 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 13/50\n",
            "train Loss: 0.0065 Acc: 0.6875\n",
            "val Loss: 0.0292 Acc: 0.6250\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 14/50\n",
            "train Loss: 0.0064 Acc: 0.6875\n",
            "val Loss: 0.0288 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 15/50\n",
            "train Loss: 0.0062 Acc: 0.7188\n",
            "val Loss: 0.0280 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 16/50\n",
            "train Loss: 0.0060 Acc: 0.7188\n",
            "val Loss: 0.0271 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 17/50\n",
            "train Loss: 0.0059 Acc: 0.7500\n",
            "val Loss: 0.0260 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 18/50\n",
            "train Loss: 0.0057 Acc: 0.7500\n",
            "val Loss: 0.0248 Acc: 0.7500\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 19/50\n",
            "train Loss: 0.0056 Acc: 0.7500\n",
            "val Loss: 0.0240 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 20/50\n",
            "train Loss: 0.0054 Acc: 0.7500\n",
            "val Loss: 0.0235 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 21/50\n",
            "train Loss: 0.0053 Acc: 0.7500\n",
            "val Loss: 0.0229 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 22/50\n",
            "train Loss: 0.0051 Acc: 0.7500\n",
            "val Loss: 0.0225 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 23/50\n",
            "train Loss: 0.0050 Acc: 0.8125\n",
            "val Loss: 0.0222 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 24/50\n",
            "train Loss: 0.0049 Acc: 0.8438\n",
            "val Loss: 0.0218 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 25/50\n",
            "train Loss: 0.0047 Acc: 0.8438\n",
            "val Loss: 0.0214 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 26/50\n",
            "train Loss: 0.0046 Acc: 0.8750\n",
            "val Loss: 0.0211 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 27/50\n",
            "train Loss: 0.0045 Acc: 0.8750\n",
            "val Loss: 0.0208 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 28/50\n",
            "train Loss: 0.0044 Acc: 0.8750\n",
            "val Loss: 0.0206 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 29/50\n",
            "train Loss: 0.0043 Acc: 0.9062\n",
            "val Loss: 0.0203 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 30/50\n",
            "train Loss: 0.0042 Acc: 0.9062\n",
            "val Loss: 0.0202 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 31/50\n",
            "train Loss: 0.0041 Acc: 0.9062\n",
            "val Loss: 0.0200 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 32/50\n",
            "train Loss: 0.0040 Acc: 0.9062\n",
            "val Loss: 0.0199 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 33/50\n",
            "train Loss: 0.0039 Acc: 0.9062\n",
            "val Loss: 0.0196 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 34/50\n",
            "train Loss: 0.0038 Acc: 0.9062\n",
            "val Loss: 0.0195 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 35/50\n",
            "train Loss: 0.0037 Acc: 0.9062\n",
            "val Loss: 0.0194 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 36/50\n",
            "train Loss: 0.0036 Acc: 0.9062\n",
            "val Loss: 0.0192 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 37/50\n",
            "train Loss: 0.0035 Acc: 0.9062\n",
            "val Loss: 0.0191 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 38/50\n",
            "train Loss: 0.0034 Acc: 0.9062\n",
            "val Loss: 0.0190 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 39/50\n",
            "train Loss: 0.0033 Acc: 0.9062\n",
            "val Loss: 0.0189 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 40/50\n",
            "train Loss: 0.0033 Acc: 0.9062\n",
            "val Loss: 0.0188 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 41/50\n",
            "train Loss: 0.0032 Acc: 0.9062\n",
            "val Loss: 0.0187 Acc: 0.8750\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 42/50\n",
            "train Loss: 0.0031 Acc: 0.9062\n",
            "val Loss: 0.0186 Acc: 1.0000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 43/50\n",
            "train Loss: 0.0030 Acc: 0.9375\n",
            "val Loss: 0.0185 Acc: 1.0000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 44/50\n",
            "train Loss: 0.0030 Acc: 0.9375\n",
            "val Loss: 0.0183 Acc: 1.0000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 45/50\n",
            "train Loss: 0.0029 Acc: 0.9375\n",
            "val Loss: 0.0182 Acc: 1.0000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 46/50\n",
            "train Loss: 0.0028 Acc: 0.9375\n",
            "val Loss: 0.0181 Acc: 1.0000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 47/50\n",
            "train Loss: 0.0028 Acc: 0.9688\n",
            "val Loss: 0.0179 Acc: 1.0000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 48/50\n",
            "train Loss: 0.0027 Acc: 0.9688\n",
            "val Loss: 0.0178 Acc: 1.0000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 49/50\n",
            "train Loss: 0.0026 Acc: 0.9688\n",
            "val Loss: 0.0177 Acc: 1.0000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "----------\n",
            "Fold 5/5 - Epoch 50/50\n",
            "train Loss: 0.0026 Acc: 0.9688\n",
            "val Loss: 0.0176 Acc: 1.0000\n",
            "Epoch complete in 0m 4s\n",
            "\n",
            "Fold 5 Training complete in 3m 12s\n",
            "Fold 5 Best val Acc: 1.000000\n",
            "\n",
            "Training complete in 16m 1s\n",
            "Best val Acc: 1.000000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT37gGo2jg4J"
      },
      "source": [
        "CAM:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRxQ2cYWjaVI",
        "outputId": "81064cb7-f515-4653-f307-f245d387a78f"
      },
      "source": [
        "import json\n",
        "\n",
        "LABELS_file = '/content/labels.json'\n",
        "\n",
        "numero = 1\n",
        "\n",
        "for image_path in images:\n",
        "  #imagem = cv2.imread(image_path)\n",
        "  imagem = Image.open(image_path)\n",
        "\n",
        "  # hook the feature extractor\n",
        "  features_blobs = []\n",
        "  def hook_feature(module, input, output):\n",
        "      features_blobs.append(output.data.cpu().numpy())\n",
        "\n",
        "  net._modules.get(finalconv_name).register_forward_hook(hook_feature)\n",
        "\n",
        "  # get the softmax weight\n",
        "  params = list(net.parameters())\n",
        "  # pega os pesos da última camada\n",
        "  weight_softmax = np.squeeze(params[-2].data.numpy())\n",
        "\n",
        "  def returnCAM(feature_conv, weight_softmax, class_idx):\n",
        "      # generate the class activation maps upsample to 256x256\n",
        "      size_upsample = (256, 256)\n",
        "      bz, nc, h, w = feature_conv.shape\n",
        "      output_cam = []\n",
        "      for idx in class_idx:\n",
        "          cam = weight_softmax[idx].dot(feature_conv.reshape((nc, h*w)))\n",
        "          cam = cam.reshape(h, w)\n",
        "          cam = cam - np.min(cam)\n",
        "          cam_img = cam / np.max(cam)\n",
        "          cam_img = np.uint8(255 * cam_img)\n",
        "          output_cam.append(cv2.resize(cam_img, size_upsample))\n",
        "      return output_cam\n",
        "\n",
        "\n",
        "  normalize = transforms.Normalize(\n",
        "    mean=[0.485, 0.456, 0.406],\n",
        "    std=[0.229, 0.224, 0.225]\n",
        "  )\n",
        "  preprocess = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "  ])\n",
        "\n",
        "  # load test image\n",
        "  #img_pil = Image.open(image_file).convert('RGB')\n",
        "  \n",
        "  print(image_path)\n",
        "  #img_pil = Image.open(imagem).convert('RGB')\n",
        "  img_pil = imagem.convert('RGB')\n",
        "  img_tensor = preprocess(img_pil)\n",
        "  img_variable = Variable(img_tensor.unsqueeze(0))\n",
        "  #logit = net(img_variable)\n",
        "  logit = trainedModel(img_variable)\n",
        "\n",
        "  # load the imagenet category list\n",
        "  with open(LABELS_file) as f:\n",
        "      classes = json.load(f)\n",
        "  #classes = [\"normal\", \"suspeito\"]\n",
        "\n",
        "\n",
        "  h_x = F.softmax(logit, dim=1).data.squeeze()\n",
        "  probs, idx = h_x.sort(0, True)\n",
        "  probs = probs.numpy()\n",
        "  idx = idx.numpy()\n",
        "\n",
        "  # output the prediction\n",
        "  for i in range(0, 2):\n",
        "      print('{:.3f} -> {}'.format(probs[i], classes[idx[i]]))\n",
        "\n",
        "  # generate class activation mapping for the top1 prediction\n",
        "  CAMs = returnCAM(features_blobs[0], weight_softmax, [idx[0]])\n",
        "\n",
        "  # render the CAM and output\n",
        "  print('output CAM.jpg for the top1 prediction: %s'%classes[idx[0]])\n",
        "  img = cv2.imread(image_path)\n",
        "  height, width, _ = img.shape\n",
        "  #height, width, _ = imagem.shape\n",
        "  heatmap = cv2.applyColorMap(cv2.resize(CAMs[0],(width, height)), cv2.COLORMAP_JET)\n",
        "  #result = heatmap * 0.5 + img * 0.3\n",
        "  result = heatmap * 0.5 + img * 0.3\n",
        "\n",
        "  #Salva o Mapa de Classe de Ativação na pasta CAMs\n",
        "  cv2.imwrite('/content/CAMs/CAM{}.jpg'.format(numero), result)\n",
        "  numero = numero + 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Dataset/benigno/benigno (10).tif\n",
            "0.530 -> normal\n",
            "0.470 -> suspeito\n",
            "output CAM.jpg for the top1 prediction: normal\n",
            "/content/Dataset/benigno/benigno (1).tif\n",
            "0.583 -> normal\n",
            "0.417 -> suspeito\n",
            "output CAM.jpg for the top1 prediction: normal\n",
            "/content/Dataset/benigno/benigno (2).tif\n",
            "0.513 -> normal\n",
            "0.487 -> suspeito\n",
            "output CAM.jpg for the top1 prediction: normal\n",
            "/content/Dataset/benigno/benigno (5).tif\n",
            "0.501 -> suspeito\n",
            "0.499 -> normal\n",
            "output CAM.jpg for the top1 prediction: suspeito\n",
            "/content/Dataset/benigno/benigno (9).tif\n",
            "0.545 -> normal\n",
            "0.455 -> suspeito\n",
            "output CAM.jpg for the top1 prediction: normal\n",
            "/content/Dataset/benigno/benigno (8).tif\n",
            "0.570 -> normal\n",
            "0.430 -> suspeito\n",
            "output CAM.jpg for the top1 prediction: normal\n",
            "/content/Dataset/benigno/benigno (12).tif\n",
            "0.519 -> normal\n",
            "0.481 -> suspeito\n",
            "output CAM.jpg for the top1 prediction: normal\n",
            "/content/Dataset/benigno/benigno (15).tif\n",
            "0.525 -> normal\n",
            "0.475 -> suspeito\n",
            "output CAM.jpg for the top1 prediction: normal\n",
            "/content/Dataset/benigno/benigno (20).tif\n",
            "0.551 -> normal\n",
            "0.449 -> suspeito\n",
            "output CAM.jpg for the top1 prediction: normal\n",
            "/content/Dataset/benigno/benigno (16).tif\n",
            "0.590 -> suspeito\n",
            "0.410 -> normal\n",
            "output CAM.jpg for the top1 prediction: suspeito\n",
            "/content/Dataset/benigno/benigno (18).tif\n",
            "0.569 -> normal\n",
            "0.431 -> suspeito\n",
            "output CAM.jpg for the top1 prediction: normal\n",
            "/content/Dataset/benigno/benigno (11).tif\n",
            "0.506 -> normal\n",
            "0.494 -> suspeito\n",
            "output CAM.jpg for the top1 prediction: normal\n",
            "/content/Dataset/benigno/benigno (6).tif\n",
            "0.519 -> normal\n",
            "0.481 -> suspeito\n",
            "output CAM.jpg for the top1 prediction: normal\n",
            "/content/Dataset/benigno/benigno (3).tif\n",
            "0.504 -> normal\n",
            "0.496 -> suspeito\n",
            "output CAM.jpg for the top1 prediction: normal\n",
            "/content/Dataset/benigno/benigno (17).tif\n",
            "0.612 -> normal\n",
            "0.388 -> suspeito\n",
            "output CAM.jpg for the top1 prediction: normal\n",
            "/content/Dataset/benigno/benigno (14).tif\n",
            "0.519 -> suspeito\n",
            "0.481 -> normal\n",
            "output CAM.jpg for the top1 prediction: suspeito\n",
            "/content/Dataset/benigno/benigno (13).tif\n",
            "0.509 -> normal\n",
            "0.491 -> suspeito\n",
            "output CAM.jpg for the top1 prediction: normal\n",
            "/content/Dataset/benigno/benigno (4).tif\n",
            "0.583 -> normal\n",
            "0.417 -> suspeito\n",
            "output CAM.jpg for the top1 prediction: normal\n",
            "/content/Dataset/benigno/benigno (7).tif\n",
            "0.582 -> normal\n",
            "0.418 -> suspeito\n",
            "output CAM.jpg for the top1 prediction: normal\n",
            "/content/Dataset/benigno/benigno (19).tif\n",
            "0.596 -> normal\n",
            "0.404 -> suspeito\n",
            "output CAM.jpg for the top1 prediction: normal\n",
            "/content/Dataset/maligno/maligno (15).tif\n",
            "0.640 -> suspeito\n",
            "0.360 -> normal\n",
            "output CAM.jpg for the top1 prediction: suspeito\n",
            "/content/Dataset/maligno/maligno (18).tif\n",
            "0.633 -> suspeito\n",
            "0.367 -> normal\n",
            "output CAM.jpg for the top1 prediction: suspeito\n",
            "/content/Dataset/maligno/maligno (14).tif\n",
            "0.513 -> suspeito\n",
            "0.487 -> normal\n",
            "output CAM.jpg for the top1 prediction: suspeito\n",
            "/content/Dataset/maligno/maligno (5).tif\n",
            "0.661 -> suspeito\n",
            "0.339 -> normal\n",
            "output CAM.jpg for the top1 prediction: suspeito\n",
            "/content/Dataset/maligno/maligno (3).tif\n",
            "0.535 -> suspeito\n",
            "0.465 -> normal\n",
            "output CAM.jpg for the top1 prediction: suspeito\n",
            "/content/Dataset/maligno/maligno (19).tif\n",
            "0.567 -> suspeito\n",
            "0.433 -> normal\n",
            "output CAM.jpg for the top1 prediction: suspeito\n",
            "/content/Dataset/maligno/maligno (4).tif\n",
            "0.644 -> suspeito\n",
            "0.356 -> normal\n",
            "output CAM.jpg for the top1 prediction: suspeito\n",
            "/content/Dataset/maligno/maligno (1).tif\n",
            "0.629 -> suspeito\n",
            "0.371 -> normal\n",
            "output CAM.jpg for the top1 prediction: suspeito\n",
            "/content/Dataset/maligno/maligno (9).tif\n",
            "0.598 -> suspeito\n",
            "0.402 -> normal\n",
            "output CAM.jpg for the top1 prediction: suspeito\n",
            "/content/Dataset/maligno/maligno (17).tif\n",
            "0.643 -> suspeito\n",
            "0.357 -> normal\n",
            "output CAM.jpg for the top1 prediction: suspeito\n",
            "/content/Dataset/maligno/maligno (8).tif\n",
            "0.548 -> suspeito\n",
            "0.452 -> normal\n",
            "output CAM.jpg for the top1 prediction: suspeito\n",
            "/content/Dataset/maligno/maligno (12).tif\n",
            "0.675 -> suspeito\n",
            "0.325 -> normal\n",
            "output CAM.jpg for the top1 prediction: suspeito\n",
            "/content/Dataset/maligno/maligno (10).tif\n",
            "0.571 -> suspeito\n",
            "0.429 -> normal\n",
            "output CAM.jpg for the top1 prediction: suspeito\n",
            "/content/Dataset/maligno/maligno (13).tif\n",
            "0.612 -> suspeito\n",
            "0.388 -> normal\n",
            "output CAM.jpg for the top1 prediction: suspeito\n",
            "/content/Dataset/maligno/maligno (2).tif\n",
            "0.512 -> normal\n",
            "0.488 -> suspeito\n",
            "output CAM.jpg for the top1 prediction: normal\n",
            "/content/Dataset/maligno/maligno (6).tif\n",
            "0.656 -> suspeito\n",
            "0.344 -> normal\n",
            "output CAM.jpg for the top1 prediction: suspeito\n",
            "/content/Dataset/maligno/maligno (16).tif\n",
            "0.672 -> suspeito\n",
            "0.328 -> normal\n",
            "output CAM.jpg for the top1 prediction: suspeito\n",
            "/content/Dataset/maligno/maligno (11).tif\n",
            "0.539 -> suspeito\n",
            "0.461 -> normal\n",
            "output CAM.jpg for the top1 prediction: suspeito\n",
            "/content/Dataset/maligno/maligno (7).tif\n",
            "0.506 -> suspeito\n",
            "0.494 -> normal\n",
            "output CAM.jpg for the top1 prediction: suspeito\n",
            "/content/Dataset/maligno/maligno (20).tif\n",
            "0.618 -> suspeito\n",
            "0.382 -> normal\n",
            "output CAM.jpg for the top1 prediction: suspeito\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmAvJIrYe8v8"
      },
      "source": [
        "import io\n",
        "from PIL import Image\n",
        "from torchvision import models, transforms\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import cv2\n",
        "import json\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "#result = cv2.imread('/content/dataset/dobermann.png')\n",
        "#numero = 1\n",
        "#for i in range(0,5):\n",
        "#  cv2.imwrite('/content/CAMs/CAM{}.jpg'.format(numero), result)\n",
        "#  numero = numero + 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}